<div class="minilivro" id="mini52">
  <h2>Scala: A LÃ­ngua da Magia por TrÃ¡s do Motor Turbo Spark! ğŸ—£ï¸âœ¨âš™ï¸</h2>
  
  <p>OlÃ¡ de novo, Desbravador(a) que fala a lÃ­ngua dos motores!</p>
  <p>
    <b>Scala</b> Ã© a linguagem nativa do Apache Spark! Combina programaÃ§Ã£o Orientada a Objetos (OOP) e Funcional (FP), roda na JVM, e Ã© a base dos motores turbo do Big Data.
  </p>
  <div class="analogia">
    <b>Analogie:</b> VocÃª pilota o Spark via PySpark ğŸğŸš¢, mas SCALA Ã© a LÃNGUA SECRETA E MÃGICA ğŸ—£ï¸âœ¨ do motor Spark â€” como os engenheiros projetaram o funcionamento interno dele!
  </div>
  <p><b>Mental Trigger:</b> SCALA = LÃ­ngua NATIVA do SPARK ğŸ—£ï¸âš™ï¸.</p>

  <h3>Por Que a LÃ­ngua do Motor Ã© Importante?</h3>
  <ul>
    <li><b>CoraÃ§Ã£o do Spark:</b> Entender Scala revela como o Spark funciona por dentro.</li>
    <li><b>Performance:</b> CÃ³digo Scala Spark pode ser mais rÃ¡pido para tarefas pesadas.</li>
    <li><b>Ecossistema:</b> Outras ferramentas Big Data (Kafka Streams, Akka) usam Scala.</li>
    <li><b>ConstruÃ§Ã£o de Ferramentas:</b> Para criar bibliotecas Spark customizadas.</li>
  </ul>

  <h3>Ferramentas e Magias BÃ¡sicas em Scala ğŸ› ï¸âœ¨</h3>
  <ul>
    <li><b>val:</b> VariÃ¡vel imutÃ¡vel. <code>val nome: String = "Moeda"</code></li>
    <li><b>var:</b> VariÃ¡vel mutÃ¡vel. <code>var valor: Double = 10.5</code></li>
    <li><b>FunÃ§Ãµes:</b> <code>def soma(x: Int, y: Int): Int = x + y</code></li>
    <li><b>FunÃ§Ãµes anÃ´nimas:</b> <code>val dobrar = (x: Int) => x * 2</code></li>
    <li><b>Case Classes:</b> Para modelar dados imutÃ¡veis.
      <pre><code>
case class ItemTesouro(nome: String, valor: Double, local: String)
val tesouro = ItemTesouro("Moeda", 10.5, "Floresta")
      </code></pre>
    </li>
    <li><b>FP:</b> Imutabilidade, funÃ§Ãµes puras, "map/filter/reduce" em coleÃ§Ãµes.</li>
  </ul>

  <h3>Scala em Apache Spark: Programando o Motor Turbo! ğŸš¢âš™ï¸</h3>
  <pre><code class="language-scala">
// Exemplo bÃ¡sico
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._

val spark = SparkSession.builder().appName("ExemploScalaSpark").getOrCreate()
val df = spark.read.parquet("s3://meu-bucket/dados/vendas_raw.parquet")
val vendasValidas = df.filter($"valor" > 0 && $"quantidade" > 0)
                      .withColumn("valor_total", $"quantidade" * $"valor")
val totalPorProduto = vendasValidas.groupBy("produto")
                                  .agg(sum($"valor_total").alias("total_vendido"))
totalPorProduto.show(10)
  </code></pre>

  <h3>Scala vs. PySpark ğŸ¤”ğŸâ†”ï¸ğŸ—£ï¸</h3>
  <ul>
    <li><b>Scala Spark:</b> API nativa, mais performÃ¡tica, tipagem estÃ¡tica, forte em FP.</li>
    <li><b>PySpark:</b> Mais fÃ¡cil/interativo para quem jÃ¡ usa Python, Ã³timo para notebooks, integraÃ§Ã£o com ecossistema Python.</li>
    <li><b>Quando usar cada:</b> Scala para desenvolvimento robusto/performance; PySpark para anÃ¡lise exploratÃ³ria e integraÃ§Ã£o Python DS.</li>
  </ul>

  <h3>Scala na Jornada de Dados ğŸ—ºï¸ğŸ—£ï¸</h3>
  <ul>
    <li>Pipelines ETL/ELT de alta performance com Spark.</li>
    <li>AplicaÃ§Ãµes de streaming (Kafka Streams, Spark Streaming).</li>
    <li>ConstruÃ§Ã£o de sistemas de dados escalÃ¡veis.</li>
  </ul>

  <h3>Recapitulando Scala! ğŸ§ ğŸ—£ï¸âœ¨âš™ï¸</h3>
  <ul>
    <li>Linguagem OOP + FP, roda na JVM.</li>
    <li>Base do Spark; Ã³tima para Big Data, performance, concorrÃªncia.</li>
    <li>Conceitos: val, var, case class, FP.</li>
    <li>Em Spark: API nativa, performance, construÃ§Ã£o de bibliotecas.</li>
    <li>ComparaÃ§Ã£o: Scala â†’ performance e robustez; PySpark â†’ facilidade e ecossistema Python.</li>
  </ul>

  <h4>PrÃ³ximos Magias a Desvendar... ğŸ—ºï¸âœ¨</h4>
  <ul>
    <li>Explorar Julia (performance numÃ©rica).</li>
    <li>Comparar Scala com outras linguagens em Big Data.</li>
    <li>Ver como Scala se encaixa na automaÃ§Ã£o e arquiteturas avanÃ§adas.</li>
  </ul>
  <p>
    Continue aprendendo novas lÃ­nguas de dados! Cada nova lÃ­ngua abre portas para soluÃ§Ãµes mais poderosas, Desbravador(a)! ğŸ’ª
  </p>
</div>
